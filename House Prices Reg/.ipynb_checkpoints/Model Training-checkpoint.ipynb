{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:42px; text-align:center; margin-bottom:30px;\"><span style=\"color:SteelBlue\"></span> Model Training</h1>\n",
    "<hr>\n",
    "\n",
    "At last, it's time to build our models! \n",
    "\n",
    "It might seem like it took us a while to get here, but professional data scientists actually spend the bulk of their time on the 3 steps leading up to this one: \n",
    "* Exploratory Analysis\n",
    "* Data Cleaning\n",
    "* Feature Engineering\n",
    "\n",
    "That's because the biggest jumps in model performance are from **better data**, not from fancier algorithms.\n",
    "\n",
    "This is lengthy and action-packed module, so buckle up and let's dive right in!\n",
    "\n",
    "<br><hr id=\"toc\">\n",
    "\n",
    "### In this module...\n",
    "\n",
    "First, we'll load our analytical base table from Module 3. \n",
    "\n",
    "Then, we'll go through the essential modeling steps:\n",
    "\n",
    "1. [Split your dataset](#split)\n",
    "2. [Build model pipelines](#pipelines)\n",
    "3. [Declare hyperparameters to tune](#hyperparameters)\n",
    "4. [Fit and tune models with cross-validation](#fit-tune)\n",
    "5. [Evaluate metrics and select winner](#evaluate)\n",
    "\n",
    "Finally, we'll save the best model as a project deliverable!\n",
    "\n",
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's import libraries, recruit models, and load the analytical base table.\n",
    "\n",
    "Let's import our libraries and load the dataset. It's good practice to keep all of your library imports at the top of your notebook or program.\n",
    "\n",
    "Before anything else, let's import the <code style=\"color:steelblue\">print()</code> function from the future for compatability with Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print function ready to serve.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function  # Compatability with Python 3\n",
    "print( 'Print function ready to serve.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import the libraries we'll need for this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy for numerical computing\n",
    "import numpy as np\n",
    "\n",
    "# Pandas for DataFrames\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# Matplotlib for visualization\n",
    "from matplotlib import pyplot as plt\n",
    "# display plots in the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Seaborn for easier visualization\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-Learn for Modeling\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import the 5 algorithms we introduced in Module 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Elastic Net, Ridge Regression, and Lasso Regression\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "\n",
    "# Import Random Forest and Gradient Boosted Trees\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Quick note about this module.</strong><br> In this module, we'll be relying heavily on Scikit-Learn, which has many helpful functions we can take advantage of. However, we won't import everything right away. Instead, we'll be importing each function from Scikit-Learn as we need it. That way, we can point out where you can find each function.\n",
    "\n",
    "\n",
    "Next, let's load the analytical base table from Module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned dataset from Module 3\n",
    "df = pd.read_csv('project_files/backup_analytical_base_table.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"split\">\n",
    "# 1. Split your dataset\n",
    "\n",
    "Let's start with a crucial but sometimes overlooked step: **Spending** your data.\n",
    "\n",
    "<br>\n",
    "First, let's import the <code style=\"color:steelblue\">train_test_split()</code> function from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for splitting training and test set\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, separate your dataframe into separate objects for the target variable (<code style=\"color:steelblue\">y</code>) and the input features (<code style=\"color:steelblue\">X</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "# Create separate object for input features\n",
    "X = df.drop('tx_price', axis = 1)\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.1</span>\n",
    "\n",
    "**First, split <code style=\"color:steelblue\">X</code> and <code style=\"color:steelblue\">y</code> into training and test sets using the <code style=\"color:steelblue\">train_test_split()</code> function.** \n",
    "* **Tip:** Its first two arguments should be X and y.\n",
    "* **Pass in the argument <code style=\"color:steelblue\">test_size=<span style=\"color:crimson\">0.2</span></code> to set aside 20% of our observations for the test set.**\n",
    "* **Pass in <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">1234</span></code> to set the random state for replicable results.**\n",
    "* You can read more about this function in the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\" target=\"_blank\">documentation</a>.\n",
    "\n",
    "The function returns a tuple with 4 elements: <code style=\"color:steelblue\">(X_train, X_test, y_train, y_test)</code>. Remember, you can **unpack** it. We've given you a head-start below with the code to unpack the tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and test sets\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X,y, test_size = 0.2, random_state = 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we have the right number of observations in each subset.\n",
    "\n",
    "<br>\n",
    "**Next, run this code to confirm the size of each subset is correct.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 373 1490 373\n"
     ]
    }
   ],
   "source": [
    "print( len(X_train), len(X_test), len(y_train), len(y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, when we train our models, we can fit them on the <code style=\"color:steelblue\">X_train</code> feature values and <code style=\"color:steelblue\">y_train</code> target values.\n",
    "\n",
    "Finally, when we're ready to evaluate our models on our test set, we would use the trained models to predict <code style=\"color:steelblue\">X_test</code> and evaluate the predictions against <code style=\"color:steelblue\">y_test</code>.\n",
    "\n",
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"pipelines\">\n",
    "# 2. Build model pipelines\n",
    "\n",
    "In Modules 1, 2, and 3, you explored the dataset, cleaned it, and engineered new features. However, sometimes we'll want to preprocess the training data even more before feeding it into our algorithms. \n",
    "\n",
    "<br>\n",
    "First, let's show the summary statistics from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.434</td>\n",
       "      <td>2.579</td>\n",
       "      <td>2322.785</td>\n",
       "      <td>12746.660</td>\n",
       "      <td>0.879</td>\n",
       "      <td>39.496</td>\n",
       "      <td>4.389</td>\n",
       "      <td>5.005</td>\n",
       "      <td>5.186</td>\n",
       "      <td>39.561</td>\n",
       "      <td>3.362</td>\n",
       "      <td>22.909</td>\n",
       "      <td>15.770</td>\n",
       "      <td>38.509</td>\n",
       "      <td>69.471</td>\n",
       "      <td>65.013</td>\n",
       "      <td>464.266</td>\n",
       "      <td>139.610</td>\n",
       "      <td>6.510</td>\n",
       "      <td>2.779</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.266</td>\n",
       "      <td>24.344</td>\n",
       "      <td>-3.731</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.073</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1297.102</td>\n",
       "      <td>34805.545</td>\n",
       "      <td>0.327</td>\n",
       "      <td>46.986</td>\n",
       "      <td>4.498</td>\n",
       "      <td>8.442</td>\n",
       "      <td>7.443</td>\n",
       "      <td>52.335</td>\n",
       "      <td>4.694</td>\n",
       "      <td>25.724</td>\n",
       "      <td>17.999</td>\n",
       "      <td>6.615</td>\n",
       "      <td>19.865</td>\n",
       "      <td>17.093</td>\n",
       "      <td>227.250</td>\n",
       "      <td>71.511</td>\n",
       "      <td>1.975</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.442</td>\n",
       "      <td>21.209</td>\n",
       "      <td>2.115</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1351.000</td>\n",
       "      <td>1542.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>53.250</td>\n",
       "      <td>321.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>-5.375</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1913.500</td>\n",
       "      <td>6183.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>426.000</td>\n",
       "      <td>125.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3014.750</td>\n",
       "      <td>11761.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>50.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>572.000</td>\n",
       "      <td>169.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>7842.000</td>\n",
       "      <td>436471.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>340.000</td>\n",
       "      <td>35.000</td>\n",
       "      <td>177.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.000</td>\n",
       "      <td>4508.000</td>\n",
       "      <td>1374.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>114.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft   lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000   1490.000  1490.000     1490.000   1490.000   \n",
       "mean     3.434    2.579 2322.785  12746.660     0.879       39.496      4.389   \n",
       "std      1.073    0.930 1297.102  34805.545     0.327       46.986      4.498   \n",
       "min      1.000    1.000  500.000      0.000     0.000        0.000      0.000   \n",
       "25%      3.000    2.000 1351.000   1542.000     1.000        6.000      1.000   \n",
       "50%      4.000    3.000 1913.500   6183.000     1.000       21.000      3.000   \n",
       "75%      4.000    3.000 3014.750  11761.000     1.000       56.000      7.000   \n",
       "max      5.000    6.000 7842.000 436471.000     1.000      266.000     24.000   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       5.005    5.186    39.561               3.362       22.909   \n",
       "std        8.442    7.443    52.335               4.694       25.724   \n",
       "min        0.000    0.000     0.000               0.000        0.000   \n",
       "25%        0.000    0.000     6.000               0.000        4.000   \n",
       "50%        2.000    3.000    20.000               2.000       15.000   \n",
       "75%        6.000    6.000    50.000               5.000       35.000   \n",
       "max       53.000   47.000   340.000              35.000      177.000   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean        15.770      38.509   69.471        65.013       464.266   \n",
       "std         17.999       6.615   19.865        17.093       227.250   \n",
       "min          0.000      22.000   11.000         5.000        88.000   \n",
       "25%          4.000      33.000   59.000        53.250       321.000   \n",
       "50%         10.000      38.000   74.000        66.000       426.000   \n",
       "75%         21.000      43.000   84.000        78.000       572.000   \n",
       "max         94.000      69.000  100.000       100.000      4508.000   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000          1490.000   \n",
       "mean     139.610          6.510        2.779        0.093             0.266   \n",
       "std       71.511          1.975        0.517        0.290             0.442   \n",
       "min       30.000          1.000        1.000        0.000             0.000   \n",
       "25%       94.000          5.000        3.000        0.000             0.000   \n",
       "50%      125.000          7.000        3.000        0.000             0.000   \n",
       "75%      169.000          8.000        3.000        0.000             1.000   \n",
       "max     1374.000         10.000        4.000        1.000             1.000   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count      1490.000      1490.000              1490.000   \n",
       "mean         24.344        -3.731                 0.360   \n",
       "std          21.209         2.115                 0.480   \n",
       "min           0.000        -8.000                 0.000   \n",
       "25%           6.000        -5.375                 0.000   \n",
       "50%          20.000        -4.000                 0.000   \n",
       "75%          38.000        -2.000                 1.000   \n",
       "max         114.000         2.000                 1.000   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.024                       0.059   \n",
       "std                          0.154                       0.236   \n",
       "min                          0.000                       0.000   \n",
       "25%                          0.000                       0.000   \n",
       "50%                          0.000                       0.000   \n",
       "75%                          0.000                       0.000   \n",
       "max                          1.000                       1.000   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.066                   0.119                 0.038   \n",
       "std                   0.248                   0.324                 0.190   \n",
       "min                   0.000                   0.000                 0.000   \n",
       "25%                   0.000                   0.000                 0.000   \n",
       "50%                   0.000                   0.000                 0.000   \n",
       "75%                   0.000                   0.000                 0.000   \n",
       "max                   1.000                   1.000                 1.000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.268                0.066         0.073   \n",
       "std                                 0.443                0.248         0.260   \n",
       "min                                 0.000                0.000         0.000   \n",
       "25%                                 0.000                0.000         0.000   \n",
       "50%                                 0.000                0.000         0.000   \n",
       "75%                                 1.000                0.000         0.000   \n",
       "max                                 1.000                1.000         1.000   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                      0.644         0.189       0.060               0.034   \n",
       "std                       0.479         0.392       0.238               0.180   \n",
       "min                       0.000         0.000       0.000               0.000   \n",
       "25%                       0.000         0.000       0.000               0.000   \n",
       "50%                       1.000         0.000       0.000               0.000   \n",
       "75%                       1.000         0.000       0.000               0.000   \n",
       "max                       1.000         1.000       1.000               1.000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.419   \n",
       "std                                          0.494   \n",
       "min                                          0.000   \n",
       "25%                                          0.000   \n",
       "50%                                          0.000   \n",
       "75%                                          1.000   \n",
       "max                                          1.000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                         0.581  \n",
       "std                          0.494  \n",
       "min                          0.000  \n",
       "25%                          0.000  \n",
       "50%                          1.000  \n",
       "75%                          1.000  \n",
       "max                          1.000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, standardize the training data manually, creating a new <code style=\"color:steelblue\">X_train_new</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize X_train\n",
    "X_train_new = (X_train - X_train.mean())/X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the summary statistics for <code style=\"color:steelblue\">X_train_new</code> to confirm standarization worked correctly.\n",
    "* How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "      <td>1490.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.269</td>\n",
       "      <td>-1.697</td>\n",
       "      <td>-1.405</td>\n",
       "      <td>-0.366</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-0.841</td>\n",
       "      <td>-0.976</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.891</td>\n",
       "      <td>-0.876</td>\n",
       "      <td>-2.496</td>\n",
       "      <td>-2.943</td>\n",
       "      <td>-3.511</td>\n",
       "      <td>-1.656</td>\n",
       "      <td>-1.533</td>\n",
       "      <td>-2.790</td>\n",
       "      <td>-3.440</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-1.148</td>\n",
       "      <td>-2.018</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.405</td>\n",
       "      <td>-0.622</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.713</td>\n",
       "      <td>-0.753</td>\n",
       "      <td>-0.593</td>\n",
       "      <td>-0.697</td>\n",
       "      <td>-0.641</td>\n",
       "      <td>-0.716</td>\n",
       "      <td>-0.735</td>\n",
       "      <td>-0.654</td>\n",
       "      <td>-0.833</td>\n",
       "      <td>-0.527</td>\n",
       "      <td>-0.688</td>\n",
       "      <td>-0.630</td>\n",
       "      <td>-0.638</td>\n",
       "      <td>-0.765</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.865</td>\n",
       "      <td>-0.777</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>-1.343</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>-1.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>-0.316</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.372</td>\n",
       "      <td>-0.394</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.356</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>-0.374</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>-0.307</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>-0.077</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.204</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>-0.749</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>-0.606</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>-0.850</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.527</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.533</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.427</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.662</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.334</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>1.650</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>-0.281</td>\n",
       "      <td>0.744</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>-0.253</td>\n",
       "      <td>-0.186</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.459</td>\n",
       "      <td>3.676</td>\n",
       "      <td>4.255</td>\n",
       "      <td>12.174</td>\n",
       "      <td>0.372</td>\n",
       "      <td>4.821</td>\n",
       "      <td>4.360</td>\n",
       "      <td>5.685</td>\n",
       "      <td>5.618</td>\n",
       "      <td>5.741</td>\n",
       "      <td>6.741</td>\n",
       "      <td>5.990</td>\n",
       "      <td>4.346</td>\n",
       "      <td>4.609</td>\n",
       "      <td>1.537</td>\n",
       "      <td>2.047</td>\n",
       "      <td>17.794</td>\n",
       "      <td>17.262</td>\n",
       "      <td>1.767</td>\n",
       "      <td>2.360</td>\n",
       "      <td>3.129</td>\n",
       "      <td>1.662</td>\n",
       "      <td>4.227</td>\n",
       "      <td>2.709</td>\n",
       "      <td>1.334</td>\n",
       "      <td>6.353</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.768</td>\n",
       "      <td>2.714</td>\n",
       "      <td>5.059</td>\n",
       "      <td>1.650</td>\n",
       "      <td>3.768</td>\n",
       "      <td>3.558</td>\n",
       "      <td>0.744</td>\n",
       "      <td>2.069</td>\n",
       "      <td>3.943</td>\n",
       "      <td>5.365</td>\n",
       "      <td>1.176</td>\n",
       "      <td>0.850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          beds    baths     sqft  lot_size  basement  restaurants  groceries  \\\n",
       "count 1490.000 1490.000 1490.000  1490.000  1490.000     1490.000   1490.000   \n",
       "mean    -0.000   -0.000    0.000     0.000     0.000        0.000      0.000   \n",
       "std      1.000    1.000    1.000     1.000     1.000        1.000      1.000   \n",
       "min     -2.269   -1.697   -1.405    -0.366    -2.688       -0.841     -0.976   \n",
       "25%     -0.405   -0.622   -0.749    -0.322     0.372       -0.713     -0.753   \n",
       "50%      0.527    0.452   -0.316    -0.189     0.372       -0.394     -0.309   \n",
       "75%      0.527    0.452    0.533    -0.028     0.372        0.351      0.581   \n",
       "max      1.459    3.676    4.255    12.174     0.372        4.821      4.360   \n",
       "\n",
       "       nightlife    cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "count   1490.000 1490.000  1490.000            1490.000     1490.000   \n",
       "mean       0.000    0.000     0.000              -0.000        0.000   \n",
       "std        1.000    1.000     1.000               1.000        1.000   \n",
       "min       -0.593   -0.697    -0.756              -0.716       -0.891   \n",
       "25%       -0.593   -0.697    -0.641              -0.716       -0.735   \n",
       "50%       -0.356   -0.294    -0.374              -0.290       -0.307   \n",
       "75%        0.118    0.109     0.199               0.349        0.470   \n",
       "max        5.685    5.618     5.741               6.741        5.990   \n",
       "\n",
       "       active_life  median_age  married  college_grad  property_tax  \\\n",
       "count     1490.000    1490.000 1490.000      1490.000      1490.000   \n",
       "mean         0.000      -0.000   -0.000        -0.000         0.000   \n",
       "std          1.000       1.000    1.000         1.000         1.000   \n",
       "min         -0.876      -2.496   -2.943        -3.511        -1.656   \n",
       "25%         -0.654      -0.833   -0.527        -0.688        -0.630   \n",
       "50%         -0.321      -0.077    0.228         0.058        -0.168   \n",
       "75%          0.291       0.679    0.731         0.760         0.474   \n",
       "max          4.346       4.609    1.537         2.047        17.794   \n",
       "\n",
       "       insurance  median_school  num_schools  two_and_two  during_recession  \\\n",
       "count   1490.000       1490.000     1490.000     1490.000          1490.000   \n",
       "mean      -0.000          0.000        0.000       -0.000            -0.000   \n",
       "std        1.000          1.000        1.000        1.000             1.000   \n",
       "min       -1.533         -2.790       -3.440       -0.319            -0.601   \n",
       "25%       -0.638         -0.765        0.427       -0.319            -0.601   \n",
       "50%       -0.204          0.248        0.427       -0.319            -0.601   \n",
       "75%        0.411          0.754        0.427       -0.319             1.662   \n",
       "max       17.262          1.767        2.360        3.129             1.662   \n",
       "\n",
       "       property_age  school_score  exterior_walls_Brick  \\\n",
       "count      1490.000      1490.000              1490.000   \n",
       "mean         -0.000        -0.000                 0.000   \n",
       "std           1.000         1.000                 1.000   \n",
       "min          -1.148        -2.018                -0.749   \n",
       "25%          -0.865        -0.777                -0.749   \n",
       "50%          -0.205        -0.127                -0.749   \n",
       "75%           0.644         0.818                 1.334   \n",
       "max           4.227         2.709                 1.334   \n",
       "\n",
       "       exterior_walls_Brick veneer  exterior_walls_Combination  \\\n",
       "count                     1490.000                    1490.000   \n",
       "mean                         0.000                       0.000   \n",
       "std                          1.000                       1.000   \n",
       "min                         -0.157                      -0.250   \n",
       "25%                         -0.157                      -0.250   \n",
       "50%                         -0.157                      -0.250   \n",
       "75%                         -0.157                      -0.250   \n",
       "max                          6.353                       3.990   \n",
       "\n",
       "       exterior_walls_Metal  exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count              1490.000                1490.000              1490.000   \n",
       "mean                  0.000                   0.000                 0.000   \n",
       "std                   1.000                   1.000                 1.000   \n",
       "min                  -0.265                  -0.368                -0.198   \n",
       "25%                  -0.265                  -0.368                -0.198   \n",
       "50%                  -0.265                  -0.368                -0.198   \n",
       "75%                  -0.265                  -0.368                -0.198   \n",
       "max                   3.768                   2.714                 5.059   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "count                            1490.000             1490.000      1490.000   \n",
       "mean                                0.000               -0.000        -0.000   \n",
       "std                                 1.000                1.000         1.000   \n",
       "min                                -0.606               -0.265        -0.281   \n",
       "25%                                -0.606               -0.265        -0.281   \n",
       "50%                                -0.606               -0.265        -0.281   \n",
       "75%                                 1.650               -0.265        -0.281   \n",
       "max                                 1.650                3.768         3.558   \n",
       "\n",
       "       roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "count                  1490.000      1490.000    1490.000            1490.000   \n",
       "mean                     -0.000         0.000      -0.000               0.000   \n",
       "std                       1.000         1.000       1.000               1.000   \n",
       "min                      -1.343        -0.483      -0.253              -0.186   \n",
       "25%                      -1.343        -0.483      -0.253              -0.186   \n",
       "50%                       0.744        -0.483      -0.253              -0.186   \n",
       "75%                       0.744        -0.483      -0.253              -0.186   \n",
       "max                       0.744         2.069       3.943               5.365   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                     1490.000   \n",
       "mean                                         0.000   \n",
       "std                                          1.000   \n",
       "min                                         -0.850   \n",
       "25%                                         -0.850   \n",
       "50%                                         -0.850   \n",
       "75%                                          1.176   \n",
       "max                                          1.176   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                     1490.000  \n",
       "mean                        -0.000  \n",
       "std                          1.000  \n",
       "min                         -1.176  \n",
       "25%                         -1.176  \n",
       "50%                          0.850  \n",
       "75%                          0.850  \n",
       "max                          0.850  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics of X_train_new\n",
    "X_train_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, we'll almost never perform manual standardization because we'll include preprocessing steps in **model pipelines**.\n",
    "\n",
    "<br>\n",
    "So let's import the <code style=\"color:steelblue\">make_pipeline()</code> function from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating model pipelines\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the <code style=\"color:steelblue\">StandardScaler</code>, which is used for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standardization\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "* It should include 3 keys: <code style=\"color:crimson\">'lasso'</code>, <code style=\"color:crimson\">'ridge'</code>, and <code style=\"color:crimson\">'enet'</code>\n",
    "* The corresponding values should be pipelines that first standardize the data.\n",
    "* For the algorithm in each pipeline, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines dictionary\n",
    "pipelines = {\n",
    "    'lasso' : make_pipeline(StandardScaler(), Lasso(random_state = 123)),\n",
    "    'ridge' : make_pipeline(StandardScaler(), Ridge(random_state = 123)),\n",
    "    'enet' : make_pipeline(StandardScaler(), ElasticNet(random_state = 123))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next exercise, you'll add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.2</span>\n",
    "\n",
    "**Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.**\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a pipeline for 'rf'\n",
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state = 123))\n",
    "# Add a pipeline for 'gb'\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state = 123))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure our dictionary has pipelines for each of our algorithms.\n",
    "\n",
    "<br>\n",
    "**Run this code to confirm that you have all 5 algorithms, each part of a pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have all 5 algorithms, and that they are all pipelines\n",
    "for key, value in pipelines.items():\n",
    "    print( key, type(value) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our pipelines, we're ready to move on to declaring hyperparameters to tune.\n",
    "\n",
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"hyperparameters\">\n",
    "# 3. Declare hyperparameters to tune\n",
    "\n",
    "Up to now, we've been casually talking about \"tuning\" models, but now it's time to treat the topic more formally.\n",
    "\n",
    "<br>\n",
    "First, list all the tunable hyperparameters for your Lasso regression pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True \n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total=   1.2s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total=   1.5s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=True, total=   1.5s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   4.6s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   6.2s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   6.3s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=True, total=   6.4s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   5.0s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   5.2s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.9s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   5.2s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   6.8s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   4.0s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   4.2s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  33.9s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   3.9s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  36.7s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False, total=   4.8s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False, total=   5.3s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  36.9s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=100, bootstrap=False, total=   5.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total=   3.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total=   3.5s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=60, bootstrap=False, total=   3.7s\n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total=  25.2s\n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total=  26.1s\n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=50, bootstrap=False, total=  26.4s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  29.1s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True, total=   4.7s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True, total=   4.3s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=70, bootstrap=True, total=   4.6s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False, total=   4.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False, total=   4.6s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=90, bootstrap=False, total=   4.4s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False, total=   8.3s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False, total=   8.2s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  28.3s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  29.8s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=10, bootstrap=False, total=   9.0s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   7.2s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total=   3.5s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   7.5s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=False, total=   7.3s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total=   4.3s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=30, bootstrap=False, total=   3.7s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False, total=  11.3s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False, total=  13.3s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  31.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  33.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  33.4s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   5.3s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.6s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.8s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=False, total=  14.0s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True, total=   8.9s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True, total=   8.0s\n",
      "[CV] n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=80, bootstrap=True, total=   8.1s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False, total=  31.1s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False, total=  32.2s\n",
      "[CV] n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=110, bootstrap=False, total=  32.7s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False, total=   9.3s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False, total=  10.1s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=30, bootstrap=False, total=   8.2s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False, total=   8.8s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   5.0s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False, total=   9.1s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   5.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=70, bootstrap=False, total=   9.4s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   5.1s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   7.7s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   7.7s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  24.6s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  22.9s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  23.7s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False, total=   2.6s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False, total=   2.7s\n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   7.7s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=False, total=   2.4s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   3.6s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   3.6s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   3.6s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False, total=  34.1s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False, total=  37.2s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=40, bootstrap=False, total=  37.8s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   5.2s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=  33.5s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.4s\n",
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.5s\n",
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.5s\n",
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.6s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.5s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total=   3.8s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total=   4.8s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=50, bootstrap=False, total=   4.3s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False, total=   4.7s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=  33.9s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False, total=   5.3s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=False, total=   4.3s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True, total=   2.3s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=  35.1s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=50, bootstrap=True, total=   2.4s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   6.5s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.8s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   6.6s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   7.1s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.4s\n",
      "[CV] n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.4s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.5s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   5.7s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   6.1s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  17.3s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  17.1s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  15.9s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  12.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   3.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   5.0s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   5.3s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  12.4s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  12.8s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True, total=   3.0s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=True, total=   3.0s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   2.8s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   2.8s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   1.4s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   3.6s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   3.3s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   1.9s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   1.8s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=90, bootstrap=True, total=   3.9s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False, total=   4.7s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False, total=   4.5s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=False, total=   4.6s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   4.8s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   4.9s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   6.1s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   2.7s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   2.4s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   1.9s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   5.1s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   5.4s\n",
      "[CV] n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True, total=  28.8s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True, total=  29.0s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=1200, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   5.2s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False, total=   2.9s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False, total=   3.1s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=110, bootstrap=False, total=   3.0s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=90, bootstrap=True, total=  29.0s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=  31.0s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False, total=  39.8s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False, total=  41.2s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=20, bootstrap=False, total=  42.6s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  7.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  17.0s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  16.8s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=  34.6s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=50, bootstrap=False, total=  13.7s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=50, bootstrap=False, total=  32.4s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  13.6s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False, total=   5.9s\n",
      "[CV] n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False, total=   5.9s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  14.2s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False, total=   2.2s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False, total=   2.7s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=60, bootstrap=False, total=   2.4s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=None, bootstrap=False, total=   6.0s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=30, bootstrap=False, total=  14.6s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True, total=  15.9s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True, total=  16.9s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=True, total=  16.8s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=  20.4s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  19.4s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=  21.1s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=80, bootstrap=True, total=  21.0s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.0s\n",
      "[CV] n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.2s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  20.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True, total=   0.9s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=1, max_features=sqrt, max_depth=50, bootstrap=True, total=   0.8s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.1s\n",
      "[CV] n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.1s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=10, bootstrap=True, total=   1.2s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.4s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=100, bootstrap=True, total=  20.0s\n",
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False, total=  13.4s\n",
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False, total=  14.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=False, total=  14.2s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.7s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.4s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  17.6s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=20, bootstrap=True, total=   4.5s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  18.2s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1200, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  17.0s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  15.8s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  15.7s\n",
      "[CV] n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=True, total=  14.8s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  23.3s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True, total=  16.3s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  25.0s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=10, bootstrap=False, total=  26.3s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True, total=  18.0s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   6.7s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   6.6s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=80, bootstrap=False, total=   6.7s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=70, bootstrap=True, total=  23.5s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   9.1s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   8.3s\n",
      "[CV] n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False \n",
      "[CV]  n_estimators=1400, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=False, total=   5.8s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   3.6s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.3s\n",
      "[CV] n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total=  41.3s\n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total=  44.7s\n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=60, bootstrap=False, total=  41.9s\n",
      "[CV] n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=20, bootstrap=False, total=   4.9s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   8.5s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   7.6s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=1800, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=60, bootstrap=True, total=   8.5s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False, total=  10.0s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False, total=   9.2s\n",
      "[CV] n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=False, total=   8.7s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False, total=   1.8s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False, total=   1.7s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=90, bootstrap=False, total=   1.7s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True, total=   6.0s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True, total=  21.8s\n",
      "[CV] n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True, total=  21.1s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True, total=   7.1s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=5, min_samples_leaf=1, max_features=auto, max_depth=90, bootstrap=True, total=  21.2s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=None, bootstrap=True, total=   8.1s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   4.0s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=  11.2s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=   9.7s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=  10.0s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   3.1s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   3.3s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True, total=   1.9s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True, total=   2.1s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=80, bootstrap=True, total=   2.1s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True, total=   6.0s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True, total=   6.7s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=100, bootstrap=True, total=   5.9s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total=   9.6s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=  31.0s\n",
      "[CV] n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=  31.0s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=60, bootstrap=False, total=  31.0s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total=  10.0s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=True, total=  10.8s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  12.4s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   3.1s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  13.3s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   3.2s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=70, bootstrap=False, total=   3.4s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False, total=   2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=   1.3s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False, total=   2.3s\n",
      "[CV] n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=False, total=   2.3s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=   1.3s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=400, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=100, bootstrap=True, total=   1.3s\n",
      "[CV] n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=None, bootstrap=False, total=  12.8s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.5s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.8s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True, total=   2.2s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=1600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=80, bootstrap=True, total=   4.5s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True, total=   2.3s\n",
      "[CV] n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=4, max_features=sqrt, max_depth=100, bootstrap=True, total=   2.3s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   2.9s\n",
      "[CV] n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   1.8s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features=sqrt, max_depth=10, bootstrap=True, total=   3.0s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   1.8s\n",
      "[CV] n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=10, min_samples_leaf=1, max_features=sqrt, max_depth=110, bootstrap=True, total=   1.8s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True, total=   2.6s\n",
      "[CV] n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False, total=   7.7s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False, total=   7.2s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=5, min_samples_leaf=4, max_features=sqrt, max_depth=None, bootstrap=False, total=   7.2s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=800, min_samples_split=5, min_samples_leaf=1, max_features=sqrt, max_depth=40, bootstrap=True, total=   2.7s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   2.3s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True, total=   5.3s\n",
      "[CV] n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True, total=   5.3s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=auto, max_depth=40, bootstrap=True, total=   5.2s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   2.4s\n",
      "[CV] n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False \n",
      "[CV]  n_estimators=600, min_samples_split=2, min_samples_leaf=4, max_features=sqrt, max_depth=30, bootstrap=False, total=   2.2s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False, total=   5.8s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False, total=   6.3s\n",
      "[CV] n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False \n",
      "[CV]  n_estimators=400, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=False, total=   6.0s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=   2.7s\n",
      "[CV] n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False \n",
      "[CV]  n_estimators=200, min_samples_split=5, min_samples_leaf=4, max_features=auto, max_depth=100, bootstrap=False, total=   2.7s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False, total=  15.5s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False, total=  15.6s\n",
      "[CV] n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   6.4s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=1000, min_samples_split=2, min_samples_leaf=1, max_features=auto, max_depth=10, bootstrap=False, total=  15.4s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   6.7s\n",
      "[CV] n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True \n",
      "[CV]  n_estimators=2000, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=20, bootstrap=True, total=   6.9s\n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True, total=  16.0s\n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True, total=  17.6s\n",
      "[CV]  n_estimators=2000, min_samples_split=10, min_samples_leaf=2, max_features=auto, max_depth=40, bootstrap=True, total=  15.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 13.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing a Random Search on Random Forest to see if it beats Grid Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score is: 0.5690715774608609\n",
      "MAE score is: 69017.34923204979\n",
      "RMSE score is: 93706.4366519749\n"
     ]
    }
   ],
   "source": [
    "pred = rf_random.predict(X_test)\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "print(\"R^2 score is:\", r2_score(y_test, pred))\n",
    "print(\"MAE score is:\", mean_absolute_error(y_test, pred))\n",
    "print(\"RMSE score is:\", np.sqrt(mean_squared_error(y_test, pred)))\n",
    "rf_random.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elasticnet': ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "       random_state=123, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'elasticnet__alpha': 1.0,\n",
       " 'elasticnet__copy_X': True,\n",
       " 'elasticnet__fit_intercept': True,\n",
       " 'elasticnet__l1_ratio': 0.5,\n",
       " 'elasticnet__max_iter': 1000,\n",
       " 'elasticnet__normalize': False,\n",
       " 'elasticnet__positive': False,\n",
       " 'elasticnet__precompute': False,\n",
       " 'elasticnet__random_state': 123,\n",
       " 'elasticnet__selection': 'cyclic',\n",
       " 'elasticnet__tol': 0.0001,\n",
       " 'elasticnet__warm_start': False,\n",
       " 'memory': None,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('elasticnet',\n",
       "   ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "         max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "         random_state=123, selection='cyclic', tol=0.0001, warm_start=False))]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List tuneable hyperparameters of our Lasso pipeline\n",
    "pipelines['enet'].get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, declare hyperparameters to tune for Lasso and Ridge regression.\n",
    "* Try values between 0.001 and 10 for <code style=\"color:steelblue\">alpha</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso hyperparameters\n",
    "lasso_hyperparameters = {'lasso__alpha' : [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "                        }\n",
    "\n",
    "# Ridge hyperparameters\n",
    "ridge_hyperparameters = {'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "                        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now declare a hyperparameter grid fo Elastic-Net.\n",
    "* You should tune the <code style=\"color:steelblue\">l1_ratio</code> in addition to <code style=\"color:steelblue\">alpha</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic Net hyperparameters\n",
    "enet_hyperparameters = {\n",
    "  'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],                        \n",
    "   'elasticnet__l1_ratio' : [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.3</span>\n",
    "\n",
    "Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "<br>\n",
    "**Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.**\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest hyperparameters\n",
    "rf_hyperparameters = {\n",
    "    'randomforestregressor__n_estimators': [200],\n",
    "    'randomforestregressor__max_features' : ['auto','sqrt', 0.33],\n",
    "    'randomforestregressor__max_depth' : [5, 8, 15, 25, 30],\n",
    "    'randomforestregressor__min_samples_split' : [2, 5, 10, 15, 100],\n",
    "     'randomforestregressor__min_samples_leaf' : [1, 2, 5, 10]  \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...timators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'randomforestregressor__n_estimators': [200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33], 'randomforestregressor__max_depth': [5, 8, 15, 25, 30], 'randomforestregressor__min_samples_split': [2, 5, 10, 15, 100], 'randomforestregressor__min_samples_leaf': [1, 2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "<br>\n",
    "**Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.**\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted tree hyperparameters\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingregressor__n_estimators': [100, 200],\n",
    "    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1, 3, 5, 7, 9, 12, 15, 17, 25],\n",
    "    'gradientboostingregressor__subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gradientboostingregressor': GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "              min_impurity_split=None, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=100, presort='auto', random_state=123,\n",
       "              subsample=1.0, verbose=0, warm_start=False),\n",
       " 'gradientboostingregressor__alpha': 0.9,\n",
       " 'gradientboostingregressor__criterion': 'friedman_mse',\n",
       " 'gradientboostingregressor__init': None,\n",
       " 'gradientboostingregressor__learning_rate': 0.1,\n",
       " 'gradientboostingregressor__loss': 'ls',\n",
       " 'gradientboostingregressor__max_depth': 3,\n",
       " 'gradientboostingregressor__max_features': None,\n",
       " 'gradientboostingregressor__max_leaf_nodes': None,\n",
       " 'gradientboostingregressor__min_impurity_decrease': 0.0,\n",
       " 'gradientboostingregressor__min_impurity_split': None,\n",
       " 'gradientboostingregressor__min_samples_leaf': 1,\n",
       " 'gradientboostingregressor__min_samples_split': 2,\n",
       " 'gradientboostingregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'gradientboostingregressor__n_estimators': 100,\n",
       " 'gradientboostingregressor__presort': 'auto',\n",
       " 'gradientboostingregressor__random_state': 123,\n",
       " 'gradientboostingregressor__subsample': 1.0,\n",
       " 'gradientboostingregressor__verbose': 0,\n",
       " 'gradientboostingregressor__warm_start': False,\n",
       " 'memory': None,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('gradientboostingregressor',\n",
       "   GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "                max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                min_impurity_split=None, min_samples_leaf=1,\n",
       "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                n_estimators=100, presort='auto', random_state=123,\n",
       "                subsample=1.0, verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.05, loss='ls', max_depth=3, max_features=None,\n",
    "             max_leaf_nodes=None, m...rs=100, presort='auto', random_state=123,\n",
    "             subsample=0.7, verbose=0, warm_start=False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "<br>\n",
    "**Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary**.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hyperparameters dictionary\n",
    "hyperparameters = {'lasso': lasso_hyperparameters, 'ridge': ridge_hyperparameters,\n",
    "                   'enet': enet_hyperparameters, 'rf' : rf_hyperparameters,\n",
    "                   'gb' : gb_hyperparameters}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso', 'ridge', 'enet', 'rf', 'gb'])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"fit-tune\">\n",
    "# 4. Fit and tune models with cross-validation\n",
    "\n",
    "Now that we have our <code style=\"color:steelblue\">pipelines</code> and <code style=\"color:steelblue\">hyperparameters</code> dictionaries declared, we're ready to tune our models with cross-validation.\n",
    "\n",
    "<br>\n",
    "First, let's to import a helper for cross-validation called <code style=\"color:steelblue\">GridSearchCV</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper for cross-validation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to see an example, set up cross-validation for Lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation object from Lasso pipeline and Lasso hyperparameters\n",
    "model = GridSearchCV(pipelines['lasso'], hyperparameters['lasso'], cv= 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code> into the <code style=\"color:steelblue\">.fit()</code> function to tune hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=123,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and tune model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, don't worry if you get the message:\n",
    "\n",
    "<pre style=\"color:crimson\">ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations</pre>\n",
    "\n",
    "We'll dive into some of the under-the-hood nuances later.\n",
    "\n",
    "<br>\n",
    "In the next exercise, we'll write a loop that tunes all of our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.4</span>\n",
    "\n",
    "**Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> that have been tuned using cross-validation.**\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_price</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>during_recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Other</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>295850</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>107</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>89</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>33.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>234.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>216500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>39.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>169.000</td>\n",
       "      <td>51.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>615</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>101</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>28.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>216.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>618</td>\n",
       "      <td>33541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>36.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>265.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>340000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>634</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>149</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>73</td>\n",
       "      <td>37.000</td>\n",
       "      <td>20.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>265000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>146</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>86</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>28.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>168.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>159</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>28.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>176.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>388100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>33541</td>\n",
       "      <td>0.000</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>36.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>266.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>36.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>188.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>119</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>183</td>\n",
       "      <td>13</td>\n",
       "      <td>70</td>\n",
       "      <td>36</td>\n",
       "      <td>57.000</td>\n",
       "      <td>13.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>147.000</td>\n",
       "      <td>51.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>335000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>148</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>34.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>248.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>376750</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>673</td>\n",
       "      <td>46609</td>\n",
       "      <td>0.000</td>\n",
       "      <td>193</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "      <td>133</td>\n",
       "      <td>10</td>\n",
       "      <td>74</td>\n",
       "      <td>86</td>\n",
       "      <td>29.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>262.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>210000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>60.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>147.000</td>\n",
       "      <td>44.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>289900</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>685</td>\n",
       "      <td>48787</td>\n",
       "      <td>0.000</td>\n",
       "      <td>189</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>64</td>\n",
       "      <td>28.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>195.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>535000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>687</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>266</td>\n",
       "      <td>12</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>328</td>\n",
       "      <td>35</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>28.000</td>\n",
       "      <td>52.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>421.000</td>\n",
       "      <td>146.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>218000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>329</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>46</td>\n",
       "      <td>32.000</td>\n",
       "      <td>33.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>188.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>126</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>84</td>\n",
       "      <td>29.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>276.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>226000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>690</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>36.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>221.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>363700</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>692</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>180</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>34</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>36.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>302.000</td>\n",
       "      <td>104.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>215000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>32.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>47.000</td>\n",
       "      <td>120.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>327000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>698</td>\n",
       "      <td>9686</td>\n",
       "      <td>0.000</td>\n",
       "      <td>146</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>27.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>256.000</td>\n",
       "      <td>88.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>331100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>9686</td>\n",
       "      <td>0.000</td>\n",
       "      <td>146</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>27.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>94.000</td>\n",
       "      <td>251.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>240000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>703</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>82</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>30.000</td>\n",
       "      <td>46.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>42.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>320000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>704</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>31.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>261.000</td>\n",
       "      <td>79.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>290800</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>704</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>34</td>\n",
       "      <td>31.000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>257.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>375000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>705</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>182</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>103</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>83</td>\n",
       "      <td>33.000</td>\n",
       "      <td>21.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>244.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>377000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>111513</td>\n",
       "      <td>0.000</td>\n",
       "      <td>213</td>\n",
       "      <td>13</td>\n",
       "      <td>44</td>\n",
       "      <td>30</td>\n",
       "      <td>108</td>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>33.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>96.000</td>\n",
       "      <td>316.000</td>\n",
       "      <td>109.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>262500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>42</td>\n",
       "      <td>36.000</td>\n",
       "      <td>49.000</td>\n",
       "      <td>77.000</td>\n",
       "      <td>201.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>216250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>53</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>19</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>36.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>187.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>270000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>33.000</td>\n",
       "      <td>48.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>218.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>765000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7001</td>\n",
       "      <td>27007</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>33.000</td>\n",
       "      <td>98.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>824.000</td>\n",
       "      <td>212.000</td>\n",
       "      <td>8.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>535000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1365</td>\n",
       "      <td>10010</td>\n",
       "      <td>1.000</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>46.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>1209.000</td>\n",
       "      <td>368.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>439000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3320</td>\n",
       "      <td>16117</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000</td>\n",
       "      <td>69.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>737.000</td>\n",
       "      <td>224.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>488085</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3696</td>\n",
       "      <td>16988</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>92.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>550.000</td>\n",
       "      <td>156.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>706095</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3720</td>\n",
       "      <td>10606</td>\n",
       "      <td>1.000</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>37.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>63.000</td>\n",
       "      <td>614.000</td>\n",
       "      <td>187.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>215000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4053</td>\n",
       "      <td>11325</td>\n",
       "      <td>1.000</td>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>42.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>696.000</td>\n",
       "      <td>212.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>700000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4189</td>\n",
       "      <td>351529</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>660.000</td>\n",
       "      <td>187.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>460000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4313</td>\n",
       "      <td>20037</td>\n",
       "      <td>1.000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>46.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>1127.000</td>\n",
       "      <td>343.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1841</th>\n",
       "      <td>800000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4600</td>\n",
       "      <td>21780</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>40.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>799.000</td>\n",
       "      <td>243.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1842</th>\n",
       "      <td>798000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4632</td>\n",
       "      <td>8712</td>\n",
       "      <td>1.000</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>95</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>42.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>938.000</td>\n",
       "      <td>286.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>755000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4658</td>\n",
       "      <td>20473</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>47.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>936.000</td>\n",
       "      <td>325.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844</th>\n",
       "      <td>350000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5000</td>\n",
       "      <td>13503</td>\n",
       "      <td>1.000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>37.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>963.000</td>\n",
       "      <td>293.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>535000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5262</td>\n",
       "      <td>10454</td>\n",
       "      <td>1.000</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>29.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>506.000</td>\n",
       "      <td>143.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>-8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>771760</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5270</td>\n",
       "      <td>11761</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>506.000</td>\n",
       "      <td>143.000</td>\n",
       "      <td>5.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>720000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5368</td>\n",
       "      <td>40946</td>\n",
       "      <td>1.000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>48.000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>83.000</td>\n",
       "      <td>1024.000</td>\n",
       "      <td>312.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>600000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5410</td>\n",
       "      <td>6777</td>\n",
       "      <td>1.000</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>39.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>1141.000</td>\n",
       "      <td>396.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>590000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5621</td>\n",
       "      <td>10890</td>\n",
       "      <td>1.000</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>42.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>67.000</td>\n",
       "      <td>1295.000</td>\n",
       "      <td>395.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>576475</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5810</td>\n",
       "      <td>8777</td>\n",
       "      <td>1.000</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>35.000</td>\n",
       "      <td>70.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>897.000</td>\n",
       "      <td>273.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>665500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6133</td>\n",
       "      <td>10001</td>\n",
       "      <td>1.000</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>39.000</td>\n",
       "      <td>78.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>1256.000</td>\n",
       "      <td>436.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>743500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6357</td>\n",
       "      <td>76665</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35.000</td>\n",
       "      <td>91.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>1127.000</td>\n",
       "      <td>343.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>535000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6438</td>\n",
       "      <td>20473</td>\n",
       "      <td>1.000</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>33.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>1106.000</td>\n",
       "      <td>337.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>765000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6508</td>\n",
       "      <td>47044</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>84.000</td>\n",
       "      <td>868.000</td>\n",
       "      <td>223.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>691331</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6966</td>\n",
       "      <td>62290</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.000</td>\n",
       "      <td>93.000</td>\n",
       "      <td>65.000</td>\n",
       "      <td>860.000</td>\n",
       "      <td>262.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>569000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7165</td>\n",
       "      <td>43995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>49.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>68.000</td>\n",
       "      <td>1024.000</td>\n",
       "      <td>312.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>235000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7594</td>\n",
       "      <td>36154</td>\n",
       "      <td>1.000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>57.000</td>\n",
       "      <td>1061.000</td>\n",
       "      <td>323.000</td>\n",
       "      <td>5.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.500</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>760000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7842</td>\n",
       "      <td>436035</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.000</td>\n",
       "      <td>76.000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>881.000</td>\n",
       "      <td>249.000</td>\n",
       "      <td>7.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>690000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6501</td>\n",
       "      <td>23086</td>\n",
       "      <td>1.000</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>42.000</td>\n",
       "      <td>73.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>1553.000</td>\n",
       "      <td>473.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>600000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7064</td>\n",
       "      <td>217800</td>\n",
       "      <td>1.000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>43.000</td>\n",
       "      <td>87.000</td>\n",
       "      <td>66.000</td>\n",
       "      <td>942.000</td>\n",
       "      <td>287.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-7.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>759900</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7500</td>\n",
       "      <td>8886</td>\n",
       "      <td>1.000</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>43.000</td>\n",
       "      <td>61.000</td>\n",
       "      <td>51.000</td>\n",
       "      <td>803.000</td>\n",
       "      <td>245.000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>735000</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7515</td>\n",
       "      <td>10497</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>37.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>86.000</td>\n",
       "      <td>1459.000</td>\n",
       "      <td>444.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tx_price  beds  baths  sqft  lot_size  basement  restaurants  groceries  \\\n",
       "0       295850     1      1   584         0     0.000          107          9   \n",
       "1       216500     1      1   612         0     1.000          105         15   \n",
       "2       279900     1      1   615         0     0.000          183         13   \n",
       "3       379900     1      1   618     33541     0.000          198          9   \n",
       "4       340000     1      1   634         0     0.000          149          7   \n",
       "5       265000     1      1   641         0     0.000          146         10   \n",
       "6       240000     1      1   642         0     0.000          159         13   \n",
       "7       388100     1      1   650     33541     0.000          198          9   \n",
       "8       240000     1      1   660         0     0.000           51          8   \n",
       "9       250000     1      1   664         0     0.000          119         10   \n",
       "10      335000     1      1   669         0     0.000          148         10   \n",
       "11      376750     1      1   673     46609     0.000          193         10   \n",
       "12      210000     1      1   680         0     1.000            8          1   \n",
       "13      289900     1      1   685     48787     0.000          189         13   \n",
       "14      535000     1      1   687         0     0.000          266         12   \n",
       "15      218000     1      1   689         0     1.000          150          6   \n",
       "16      400000     1      1   689         0     0.000          198          9   \n",
       "17      226000     1      1   690         0     1.000           60          3   \n",
       "18      363700     1      1   692         0     0.000          180         14   \n",
       "19      215000     1      1   698         0     0.000           31          6   \n",
       "20      327000     1      1   698      9686     0.000          146          7   \n",
       "21      331100     1      1   700      9686     0.000          146          7   \n",
       "22      240000     1      1   703         0     1.000           82          6   \n",
       "23      320000     1      1   704         0     1.000           99          8   \n",
       "24      290800     1      1   704         0     1.000           99          9   \n",
       "25      375000     1      1   705         0     0.000          182         10   \n",
       "26      377000     1      1   709    111513     0.000          213         13   \n",
       "27      262500     1      1   711         0     0.000           51          9   \n",
       "28      216250     1      1   712         0     0.000           53         13   \n",
       "29      270000     1      1   722         0     1.000          101          8   \n",
       "...        ...   ...    ...   ...       ...       ...          ...        ...   \n",
       "1833    765000     5      4  7001     27007     1.000           14          3   \n",
       "1834    535000     5      5  1365     10010     1.000           30          2   \n",
       "1835    439000     5      5  3320     16117     1.000            4          1   \n",
       "1836    488085     5      5  3696     16988     1.000            2          0   \n",
       "1837    706095     5      5  3720     10606     1.000           12         10   \n",
       "1838    215000     5      5  4053     11325     1.000           71          7   \n",
       "1839    700000     5      5  4189    351529     1.000            0          0   \n",
       "1840    460000     5      5  4313     20037     1.000            6          1   \n",
       "1841    800000     5      5  4600     21780     1.000            1          0   \n",
       "1842    798000     5      5  4632      8712     1.000           58          6   \n",
       "1843    755000     5      5  4658     20473     1.000           15          2   \n",
       "1844    350000     5      5  5000     13503     1.000           22          0   \n",
       "1845    535000     5      5  5262     10454     1.000           23          2   \n",
       "1846    771760     5      5  5270     11761     1.000            0          0   \n",
       "1847    720000     5      5  5368     40946     1.000            4          1   \n",
       "1848    600000     5      5  5410      6777     1.000           32          6   \n",
       "1849    590000     5      5  5621     10890     1.000           42          4   \n",
       "1850    576475     5      5  5810      8777     1.000           13          2   \n",
       "1851    665500     5      5  6133     10001     1.000           34          1   \n",
       "1852    743500     5      5  6357     76665     1.000            3          0   \n",
       "1853    535000     5      5  6438     20473     1.000           57          7   \n",
       "1854    765000     5      5  6508     47044     1.000            0          0   \n",
       "1855    691331     5      5  6966     62290     1.000            0          0   \n",
       "1856    569000     5      5  7165     43995     1.000            9          1   \n",
       "1857    235000     5      5  7594     36154     1.000            8          1   \n",
       "1858    760000     5      5  7842    436035     1.000            0          0   \n",
       "1859    690000     5      6  6501     23086     1.000           45          7   \n",
       "1860    600000     5      6  7064    217800     1.000            5          1   \n",
       "1861    759900     5      6  7500      8886     1.000           18          2   \n",
       "1862    735000     5      6  7515     10497     1.000            0          0   \n",
       "\n",
       "      nightlife  cafes  shopping  arts_entertainment  beauty_spas  \\\n",
       "0            30     19        89                   6           47   \n",
       "1             6     13        87                   2           26   \n",
       "2            31     30       101                  10           74   \n",
       "3            38     25       127                  11           72   \n",
       "4            22     20        83                  10           50   \n",
       "5            23     27        86                   9           60   \n",
       "6            36     17        92                  12           66   \n",
       "7            38     25       127                  11           72   \n",
       "8             6      2        40                  18           32   \n",
       "9            26     25       183                  13           70   \n",
       "10           27     23        57                   5           37   \n",
       "11           37     27       133                  10           74   \n",
       "12            0      3        10                   1           10   \n",
       "13           37     31       102                  11           75   \n",
       "14           54     45       328                  35          126   \n",
       "15           20     27       329                  12           83   \n",
       "16           38     25       126                  12           72   \n",
       "17            9     15       156                   3           30   \n",
       "18           37     34       104                  13           72   \n",
       "19            5      8        32                   2           19   \n",
       "20           22     20        79                  10           49   \n",
       "21           22     20        79                  10           49   \n",
       "22            7      8        45                   6           52   \n",
       "23            8     11       103                   4           47   \n",
       "24            8     11       103                   4           46   \n",
       "25           31     25       103                  10           63   \n",
       "26           44     30       108                  11           91   \n",
       "27            6      2        43                  18           35   \n",
       "28            7      3        43                  19           43   \n",
       "29            8     11        74                   4           30   \n",
       "...         ...    ...       ...                 ...          ...   \n",
       "1833          1      3        10                   0           12   \n",
       "1834          2      2        41                   3           22   \n",
       "1835          1      0         8                   3            2   \n",
       "1836          1      0         2                   0            3   \n",
       "1837          1      0        22                   0           21   \n",
       "1838          6      9        87                   4           32   \n",
       "1839          0      0         1                   0            0   \n",
       "1840          0      1         8                   1            7   \n",
       "1841          0      0         2                   0            1   \n",
       "1842          7     11        95                   4           34   \n",
       "1843          0      1        17                   4            7   \n",
       "1844          4      3        19                   2           14   \n",
       "1845          2      2        26                   2           15   \n",
       "1846          0      0         1                   0            1   \n",
       "1847          2      2         4                   0           15   \n",
       "1848          4      6        40                   6           23   \n",
       "1849          2      3        48                   1           17   \n",
       "1850          0      1        17                   0           18   \n",
       "1851          7      4        39                   5           25   \n",
       "1852          0      0         4                   0            1   \n",
       "1853          4      9        88                   9           82   \n",
       "1854          0      0         1                   0            0   \n",
       "1855          0      0         1                   0            0   \n",
       "1856          1      1        11                   1            3   \n",
       "1857          0      1         5                   4            5   \n",
       "1858          0      0         0                   0            0   \n",
       "1859          5      7        41                   3           61   \n",
       "1860          1      1         8                   2            1   \n",
       "1861          4      0         5                   1            8   \n",
       "1862          0      1         2                   2            0   \n",
       "\n",
       "      active_life  median_age  married  college_grad  property_tax  insurance  \\\n",
       "0              58      33.000   65.000        84.000       234.000     81.000   \n",
       "1              14      39.000   73.000        69.000       169.000     51.000   \n",
       "2              62      28.000   15.000        86.000       216.000     74.000   \n",
       "3              83      36.000   25.000        91.000       265.000     92.000   \n",
       "4              73      37.000   20.000        75.000        88.000     30.000   \n",
       "5              52      28.000   15.000        86.000       168.000     58.000   \n",
       "6              50      28.000   36.000        88.000       176.000     61.000   \n",
       "7              83      36.000   25.000        91.000       266.000     92.000   \n",
       "8              41      36.000   49.000        77.000       188.000     65.000   \n",
       "9              36      57.000   13.000        83.000       147.000     51.000   \n",
       "10             29      34.000   29.000        88.000       248.000     86.000   \n",
       "11             86      29.000   15.000        82.000       262.000     90.000   \n",
       "12             10      60.000   15.000        63.000       147.000     44.000   \n",
       "13             64      28.000   15.000        86.000       195.000     68.000   \n",
       "14             88      28.000   52.000        72.000       421.000    146.000   \n",
       "15             46      32.000   33.000        92.000       188.000     57.000   \n",
       "16             84      29.000   15.000        82.000       276.000     96.000   \n",
       "17             12      36.000   47.000        83.000       221.000     67.000   \n",
       "18             68      36.000   25.000        75.000       302.000    104.000   \n",
       "19             14      32.000   60.000        47.000       120.000     42.000   \n",
       "20             74      27.000   21.000        94.000       256.000     88.000   \n",
       "21             74      27.000   21.000        94.000       251.000     87.000   \n",
       "22             13      30.000   46.000        36.000       139.000     42.000   \n",
       "23             34      31.000   30.000        99.000       261.000     79.000   \n",
       "24             34      31.000   30.000        99.000       257.000     78.000   \n",
       "25             83      33.000   21.000        99.000       244.000     85.000   \n",
       "26             88      33.000   40.000        96.000       316.000    109.000   \n",
       "27             42      36.000   49.000        77.000       201.000     69.000   \n",
       "28             41      36.000   23.000        90.000       187.000     64.000   \n",
       "29             26      33.000   48.000        85.000       218.000     66.000   \n",
       "...           ...         ...      ...           ...           ...        ...   \n",
       "1833            8      33.000   98.000        83.000       824.000    212.000   \n",
       "1834           25      46.000   75.000        66.000      1209.000    368.000   \n",
       "1835            1      50.000   69.000        81.000       737.000    224.000   \n",
       "1836            1      33.000   92.000        64.000       550.000    156.000   \n",
       "1837            6      37.000   82.000        63.000       614.000    187.000   \n",
       "1838           31      42.000   74.000        67.000       696.000    212.000   \n",
       "1839            0      41.000   67.000        24.000       660.000    187.000   \n",
       "1840            6      46.000   83.000        87.000      1127.000    343.000   \n",
       "1841            4      40.000   86.000        74.000       799.000    243.000   \n",
       "1842           25      42.000   76.000        64.000       938.000    286.000   \n",
       "1843           17      47.000   80.000        91.000       936.000    325.000   \n",
       "1844           21      37.000   90.000        74.000       963.000    293.000   \n",
       "1845            9      29.000   81.000        41.000       506.000    143.000   \n",
       "1846            3      42.000   84.000        58.000       506.000    143.000   \n",
       "1847            6      48.000   90.000        83.000      1024.000    312.000   \n",
       "1848           39      39.000   66.000        80.000      1141.000    396.000   \n",
       "1849           17      42.000   74.000        67.000      1295.000    395.000   \n",
       "1850            6      35.000   70.000        73.000       897.000    273.000   \n",
       "1851           32      39.000   78.000        74.000      1256.000    436.000   \n",
       "1852            2      35.000   91.000        85.000      1127.000    343.000   \n",
       "1853           26      33.000   74.000        80.000      1106.000    337.000   \n",
       "1854            1      37.000   74.000        84.000       868.000    223.000   \n",
       "1855            1      46.000   93.000        65.000       860.000    262.000   \n",
       "1856            6      49.000   82.000        68.000      1024.000    312.000   \n",
       "1857            2      52.000   85.000        57.000      1061.000    323.000   \n",
       "1858            0      48.000   76.000        62.000       881.000    249.000   \n",
       "1859           11      42.000   73.000        61.000      1553.000    473.000   \n",
       "1860            2      43.000   87.000        66.000       942.000    287.000   \n",
       "1861            6      43.000   61.000        51.000       803.000    245.000   \n",
       "1862            5      37.000   80.000        86.000      1459.000    444.000   \n",
       "\n",
       "      median_school  num_schools  two_and_two  during_recession  property_age  \\\n",
       "0             9.000        3.000            0                 1             0   \n",
       "1             3.000        3.000            0                 0            41   \n",
       "2             8.000        3.000            0                 1            49   \n",
       "3             9.000        3.000            0                 0             5   \n",
       "4             9.000        3.000            0                 0            10   \n",
       "5             8.000        3.000            0                 0            57   \n",
       "6             7.000        3.000            0                 1            67   \n",
       "7             9.000        3.000            0                 0             5   \n",
       "8             6.000        3.000            0                 1            30   \n",
       "9             6.000        3.000            0                 0            42   \n",
       "10            6.000        3.000            0                 0             9   \n",
       "11            9.000        3.000            0                 0             1   \n",
       "12            4.000        3.000            0                 0            43   \n",
       "13            8.000        3.000            0                 0            45   \n",
       "14            8.000        3.000            0                 0             6   \n",
       "15           10.000        3.000            0                 0            21   \n",
       "16            9.000        3.000            0                 0             8   \n",
       "17            8.000        3.000            0                 0            11   \n",
       "18            8.000        3.000            0                 0             0   \n",
       "19            7.000        3.000            0                 0            42   \n",
       "20            9.000        3.000            0                 1             5   \n",
       "21            9.000        3.000            0                 1             7   \n",
       "22            7.000        3.000            0                 0            13   \n",
       "23            8.000        3.000            0                 0             2   \n",
       "24            8.000        3.000            0                 0             0   \n",
       "25            9.000        3.000            0                 0            20   \n",
       "26            5.000        3.000            0                 0             3   \n",
       "27            6.000        3.000            0                 0            70   \n",
       "28            6.000        3.000            0                 0            60   \n",
       "29            4.000        3.000            0                 0            20   \n",
       "...             ...          ...          ...               ...           ...   \n",
       "1833          8.500        2.000            0                 0             4   \n",
       "1834         10.000        3.000            0                 0            64   \n",
       "1835          6.000        3.000            0                 1            66   \n",
       "1836          9.000        1.000            0                 0             0   \n",
       "1837          3.000        3.000            0                 0             0   \n",
       "1838          9.000        3.000            0                 0            38   \n",
       "1839          8.000        3.000            0                 1             4   \n",
       "1840         10.000        3.000            0                 0            35   \n",
       "1841          6.000        3.000            0                 1            46   \n",
       "1842          8.000        3.000            0                 1             7   \n",
       "1843          9.000        3.000            0                 0            34   \n",
       "1844         10.000        3.000            0                 0            51   \n",
       "1845          9.000        1.000            0                 1            11   \n",
       "1846          5.500        2.000            0                 0             0   \n",
       "1847         10.000        3.000            0                 0             3   \n",
       "1848          9.000        3.000            0                 0            63   \n",
       "1849          9.000        3.000            0                 0            44   \n",
       "1850          8.000        3.000            0                 0             0   \n",
       "1851          9.000        3.000            0                 0            64   \n",
       "1852         10.000        3.000            0                 0             9   \n",
       "1853          9.000        3.000            0                 1            63   \n",
       "1854          7.000        3.000            0                 0             2   \n",
       "1855          8.000        3.000            0                 0             0   \n",
       "1856          8.000        2.000            0                 0             3   \n",
       "1857          5.500        2.000            0                 0             0   \n",
       "1858          7.500        2.000            0                 0             5   \n",
       "1859          9.000        3.000            0                 0            59   \n",
       "1860          8.000        1.000            0                 0             4   \n",
       "1861          5.000        2.000            0                 0             3   \n",
       "1862          9.000        3.000            0                 0            57   \n",
       "\n",
       "      school_score  exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "0           -6.000                 0.000                        0.000   \n",
       "1            0.000                 1.000                        0.000   \n",
       "2           -5.000                 0.000                        0.000   \n",
       "3           -6.000                 0.000                        0.000   \n",
       "4           -6.000                 1.000                        0.000   \n",
       "5           -5.000                 1.000                        0.000   \n",
       "6           -4.000                 1.000                        0.000   \n",
       "7           -6.000                 0.000                        0.000   \n",
       "8           -3.000                 1.000                        0.000   \n",
       "9           -3.000                 1.000                        0.000   \n",
       "10          -3.000                 0.000                        0.000   \n",
       "11          -6.000                 0.000                        0.000   \n",
       "12          -1.000                 1.000                        0.000   \n",
       "13          -5.000                 1.000                        0.000   \n",
       "14          -5.000                 0.000                        0.000   \n",
       "15          -7.000                 1.000                        0.000   \n",
       "16          -6.000                 0.000                        0.000   \n",
       "17          -5.000                 1.000                        0.000   \n",
       "18          -5.000                 1.000                        0.000   \n",
       "19          -4.000                 1.000                        0.000   \n",
       "20          -6.000                 0.000                        0.000   \n",
       "21          -6.000                 0.000                        0.000   \n",
       "22          -4.000                 0.000                        0.000   \n",
       "23          -5.000                 1.000                        0.000   \n",
       "24          -5.000                 1.000                        0.000   \n",
       "25          -6.000                 1.000                        0.000   \n",
       "26          -2.000                 0.000                        0.000   \n",
       "27          -3.000                 1.000                        0.000   \n",
       "28          -3.000                 1.000                        0.000   \n",
       "29          -1.000                 0.000                        0.000   \n",
       "...            ...                   ...                          ...   \n",
       "1833        -6.500                 0.000                        0.000   \n",
       "1834        -7.000                 0.000                        0.000   \n",
       "1835        -3.000                 0.000                        0.000   \n",
       "1836        -8.000                 0.000                        0.000   \n",
       "1837         0.000                 0.000                        0.000   \n",
       "1838        -6.000                 0.000                        0.000   \n",
       "1839        -5.000                 0.000                        0.000   \n",
       "1840        -7.000                 1.000                        0.000   \n",
       "1841        -3.000                 1.000                        0.000   \n",
       "1842        -5.000                 0.000                        0.000   \n",
       "1843        -6.000                 0.000                        1.000   \n",
       "1844        -7.000                 0.000                        0.000   \n",
       "1845        -8.000                 0.000                        0.000   \n",
       "1846        -3.500                 0.000                        0.000   \n",
       "1847        -7.000                 1.000                        0.000   \n",
       "1848        -6.000                 0.000                        1.000   \n",
       "1849        -6.000                 1.000                        0.000   \n",
       "1850        -5.000                 0.000                        0.000   \n",
       "1851        -6.000                 0.000                        1.000   \n",
       "1852        -7.000                 1.000                        0.000   \n",
       "1853        -6.000                 0.000                        0.000   \n",
       "1854        -4.000                 0.000                        0.000   \n",
       "1855        -5.000                 0.000                        0.000   \n",
       "1856        -6.000                 1.000                        0.000   \n",
       "1857        -3.500                 1.000                        0.000   \n",
       "1858        -5.500                 0.000                        0.000   \n",
       "1859        -6.000                 1.000                        0.000   \n",
       "1860        -7.000                 0.000                        0.000   \n",
       "1861        -3.000                 0.000                        0.000   \n",
       "1862        -6.000                 1.000                        0.000   \n",
       "\n",
       "      exterior_walls_Combination  exterior_walls_Metal  \\\n",
       "0                          0.000                 0.000   \n",
       "1                          0.000                 0.000   \n",
       "2                          0.000                 0.000   \n",
       "3                          0.000                 0.000   \n",
       "4                          0.000                 0.000   \n",
       "5                          0.000                 0.000   \n",
       "6                          0.000                 0.000   \n",
       "7                          0.000                 0.000   \n",
       "8                          0.000                 0.000   \n",
       "9                          0.000                 0.000   \n",
       "10                         0.000                 0.000   \n",
       "11                         0.000                 0.000   \n",
       "12                         0.000                 0.000   \n",
       "13                         0.000                 0.000   \n",
       "14                         0.000                 0.000   \n",
       "15                         0.000                 0.000   \n",
       "16                         0.000                 0.000   \n",
       "17                         0.000                 0.000   \n",
       "18                         0.000                 0.000   \n",
       "19                         0.000                 0.000   \n",
       "20                         0.000                 0.000   \n",
       "21                         0.000                 0.000   \n",
       "22                         0.000                 0.000   \n",
       "23                         0.000                 0.000   \n",
       "24                         0.000                 0.000   \n",
       "25                         0.000                 0.000   \n",
       "26                         0.000                 0.000   \n",
       "27                         0.000                 0.000   \n",
       "28                         0.000                 0.000   \n",
       "29                         0.000                 0.000   \n",
       "...                          ...                   ...   \n",
       "1833                       0.000                 0.000   \n",
       "1834                       0.000                 0.000   \n",
       "1835                       0.000                 0.000   \n",
       "1836                       1.000                 0.000   \n",
       "1837                       0.000                 0.000   \n",
       "1838                       0.000                 0.000   \n",
       "1839                       0.000                 0.000   \n",
       "1840                       0.000                 0.000   \n",
       "1841                       0.000                 0.000   \n",
       "1842                       0.000                 0.000   \n",
       "1843                       0.000                 0.000   \n",
       "1844                       0.000                 0.000   \n",
       "1845                       1.000                 0.000   \n",
       "1846                       1.000                 0.000   \n",
       "1847                       0.000                 0.000   \n",
       "1848                       0.000                 0.000   \n",
       "1849                       0.000                 0.000   \n",
       "1850                       0.000                 0.000   \n",
       "1851                       0.000                 0.000   \n",
       "1852                       0.000                 0.000   \n",
       "1853                       0.000                 0.000   \n",
       "1854                       0.000                 0.000   \n",
       "1855                       0.000                 0.000   \n",
       "1856                       0.000                 0.000   \n",
       "1857                       0.000                 0.000   \n",
       "1858                       1.000                 0.000   \n",
       "1859                       0.000                 0.000   \n",
       "1860                       0.000                 1.000   \n",
       "1861                       0.000                 0.000   \n",
       "1862                       0.000                 0.000   \n",
       "\n",
       "      exterior_walls_Missing  exterior_walls_Other  \\\n",
       "0                      0.000                 0.000   \n",
       "1                      0.000                 0.000   \n",
       "2                      0.000                 0.000   \n",
       "3                      0.000                 0.000   \n",
       "4                      0.000                 0.000   \n",
       "5                      0.000                 0.000   \n",
       "6                      0.000                 0.000   \n",
       "7                      0.000                 0.000   \n",
       "8                      0.000                 0.000   \n",
       "9                      0.000                 0.000   \n",
       "10                     0.000                 0.000   \n",
       "11                     0.000                 1.000   \n",
       "12                     0.000                 0.000   \n",
       "13                     0.000                 0.000   \n",
       "14                     0.000                 0.000   \n",
       "15                     0.000                 0.000   \n",
       "16                     0.000                 0.000   \n",
       "17                     0.000                 0.000   \n",
       "18                     0.000                 0.000   \n",
       "19                     0.000                 0.000   \n",
       "20                     0.000                 1.000   \n",
       "21                     0.000                 1.000   \n",
       "22                     0.000                 0.000   \n",
       "23                     0.000                 0.000   \n",
       "24                     0.000                 0.000   \n",
       "25                     0.000                 0.000   \n",
       "26                     0.000                 0.000   \n",
       "27                     0.000                 0.000   \n",
       "28                     0.000                 0.000   \n",
       "29                     0.000                 0.000   \n",
       "...                      ...                   ...   \n",
       "1833                   1.000                 0.000   \n",
       "1834                   0.000                 0.000   \n",
       "1835                   0.000                 0.000   \n",
       "1836                   0.000                 0.000   \n",
       "1837                   0.000                 0.000   \n",
       "1838                   0.000                 0.000   \n",
       "1839                   0.000                 0.000   \n",
       "1840                   0.000                 0.000   \n",
       "1841                   0.000                 0.000   \n",
       "1842                   0.000                 0.000   \n",
       "1843                   0.000                 0.000   \n",
       "1844                   0.000                 0.000   \n",
       "1845                   0.000                 0.000   \n",
       "1846                   0.000                 0.000   \n",
       "1847                   0.000                 0.000   \n",
       "1848                   0.000                 0.000   \n",
       "1849                   0.000                 0.000   \n",
       "1850                   0.000                 0.000   \n",
       "1851                   0.000                 0.000   \n",
       "1852                   0.000                 0.000   \n",
       "1853                   0.000                 1.000   \n",
       "1854                   1.000                 0.000   \n",
       "1855                   0.000                 0.000   \n",
       "1856                   0.000                 0.000   \n",
       "1857                   0.000                 0.000   \n",
       "1858                   0.000                 0.000   \n",
       "1859                   0.000                 0.000   \n",
       "1860                   0.000                 0.000   \n",
       "1861                   0.000                 0.000   \n",
       "1862                   0.000                 0.000   \n",
       "\n",
       "      exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  roof_Asphalt  \\\n",
       "0                                  0.000                1.000         0.000   \n",
       "1                                  0.000                0.000         0.000   \n",
       "2                                  0.000                1.000         0.000   \n",
       "3                                  0.000                1.000         0.000   \n",
       "4                                  0.000                0.000         0.000   \n",
       "5                                  0.000                0.000         0.000   \n",
       "6                                  0.000                0.000         0.000   \n",
       "7                                  0.000                1.000         0.000   \n",
       "8                                  0.000                0.000         0.000   \n",
       "9                                  0.000                0.000         0.000   \n",
       "10                                 0.000                1.000         0.000   \n",
       "11                                 0.000                0.000         0.000   \n",
       "12                                 0.000                0.000         0.000   \n",
       "13                                 0.000                0.000         0.000   \n",
       "14                                 0.000                1.000         0.000   \n",
       "15                                 0.000                0.000         0.000   \n",
       "16                                 0.000                1.000         0.000   \n",
       "17                                 0.000                0.000         0.000   \n",
       "18                                 0.000                0.000         0.000   \n",
       "19                                 0.000                0.000         0.000   \n",
       "20                                 0.000                0.000         0.000   \n",
       "21                                 0.000                0.000         0.000   \n",
       "22                                 0.000                1.000         0.000   \n",
       "23                                 0.000                0.000         0.000   \n",
       "24                                 0.000                0.000         0.000   \n",
       "25                                 0.000                0.000         0.000   \n",
       "26                                 0.000                1.000         0.000   \n",
       "27                                 0.000                0.000         0.000   \n",
       "28                                 0.000                0.000         0.000   \n",
       "29                                 1.000                0.000         0.000   \n",
       "...                                  ...                  ...           ...   \n",
       "1833                               0.000                0.000         0.000   \n",
       "1834                               1.000                0.000         0.000   \n",
       "1835                               1.000                0.000         0.000   \n",
       "1836                               0.000                0.000         0.000   \n",
       "1837                               1.000                0.000         0.000   \n",
       "1838                               1.000                0.000         0.000   \n",
       "1839                               1.000                0.000         0.000   \n",
       "1840                               0.000                0.000         0.000   \n",
       "1841                               0.000                0.000         0.000   \n",
       "1842                               1.000                0.000         0.000   \n",
       "1843                               0.000                0.000         1.000   \n",
       "1844                               1.000                0.000         0.000   \n",
       "1845                               0.000                0.000         0.000   \n",
       "1846                               0.000                0.000         0.000   \n",
       "1847                               0.000                0.000         0.000   \n",
       "1848                               0.000                0.000         0.000   \n",
       "1849                               0.000                0.000         0.000   \n",
       "1850                               0.000                1.000         0.000   \n",
       "1851                               0.000                0.000         0.000   \n",
       "1852                               0.000                0.000         0.000   \n",
       "1853                               0.000                0.000         0.000   \n",
       "1854                               0.000                0.000         0.000   \n",
       "1855                               1.000                0.000         0.000   \n",
       "1856                               0.000                0.000         0.000   \n",
       "1857                               0.000                0.000         0.000   \n",
       "1858                               0.000                0.000         0.000   \n",
       "1859                               0.000                0.000         0.000   \n",
       "1860                               0.000                0.000         0.000   \n",
       "1861                               1.000                0.000         1.000   \n",
       "1862                               0.000                0.000         0.000   \n",
       "\n",
       "      roof_Composition Shingle  roof_Missing  roof_Other  roof_Shake Shingle  \\\n",
       "0                        0.000         1.000       0.000               0.000   \n",
       "1                        1.000         0.000       0.000               0.000   \n",
       "2                        0.000         1.000       0.000               0.000   \n",
       "3                        0.000         1.000       0.000               0.000   \n",
       "4                        0.000         1.000       0.000               0.000   \n",
       "5                        0.000         1.000       0.000               0.000   \n",
       "6                        0.000         1.000       0.000               0.000   \n",
       "7                        0.000         1.000       0.000               0.000   \n",
       "8                        0.000         1.000       0.000               0.000   \n",
       "9                        0.000         1.000       0.000               0.000   \n",
       "10                       0.000         1.000       0.000               0.000   \n",
       "11                       0.000         1.000       0.000               0.000   \n",
       "12                       1.000         0.000       0.000               0.000   \n",
       "13                       0.000         1.000       0.000               0.000   \n",
       "14                       0.000         1.000       0.000               0.000   \n",
       "15                       1.000         0.000       0.000               0.000   \n",
       "16                       0.000         1.000       0.000               0.000   \n",
       "17                       1.000         0.000       0.000               0.000   \n",
       "18                       0.000         1.000       0.000               0.000   \n",
       "19                       0.000         1.000       0.000               0.000   \n",
       "20                       0.000         1.000       0.000               0.000   \n",
       "21                       0.000         1.000       0.000               0.000   \n",
       "22                       1.000         0.000       0.000               0.000   \n",
       "23                       1.000         0.000       0.000               0.000   \n",
       "24                       1.000         0.000       0.000               0.000   \n",
       "25                       0.000         1.000       0.000               0.000   \n",
       "26                       0.000         1.000       0.000               0.000   \n",
       "27                       0.000         1.000       0.000               0.000   \n",
       "28                       0.000         1.000       0.000               0.000   \n",
       "29                       1.000         0.000       0.000               0.000   \n",
       "...                        ...           ...         ...                 ...   \n",
       "1833                     1.000         0.000       0.000               0.000   \n",
       "1834                     1.000         0.000       0.000               0.000   \n",
       "1835                     0.000         0.000       0.000               1.000   \n",
       "1836                     0.000         1.000       0.000               0.000   \n",
       "1837                     1.000         0.000       0.000               0.000   \n",
       "1838                     0.000         0.000       0.000               1.000   \n",
       "1839                     1.000         0.000       0.000               0.000   \n",
       "1840                     1.000         0.000       0.000               0.000   \n",
       "1841                     1.000         0.000       0.000               0.000   \n",
       "1842                     1.000         0.000       0.000               0.000   \n",
       "1843                     0.000         0.000       0.000               0.000   \n",
       "1844                     1.000         0.000       0.000               0.000   \n",
       "1845                     0.000         1.000       0.000               0.000   \n",
       "1846                     1.000         0.000       0.000               0.000   \n",
       "1847                     1.000         0.000       0.000               0.000   \n",
       "1848                     1.000         0.000       0.000               0.000   \n",
       "1849                     0.000         0.000       1.000               0.000   \n",
       "1850                     1.000         0.000       0.000               0.000   \n",
       "1851                     1.000         0.000       0.000               0.000   \n",
       "1852                     0.000         0.000       1.000               0.000   \n",
       "1853                     1.000         0.000       0.000               0.000   \n",
       "1854                     1.000         0.000       0.000               0.000   \n",
       "1855                     0.000         0.000       1.000               0.000   \n",
       "1856                     1.000         0.000       0.000               0.000   \n",
       "1857                     1.000         0.000       0.000               0.000   \n",
       "1858                     0.000         1.000       0.000               0.000   \n",
       "1859                     1.000         0.000       0.000               0.000   \n",
       "1860                     1.000         0.000       0.000               0.000   \n",
       "1861                     0.000         0.000       0.000               0.000   \n",
       "1862                     1.000         0.000       0.000               0.000   \n",
       "\n",
       "      property_type_Apartment / Condo / Townhouse  property_type_Single-Family  \n",
       "0                                           1.000                        0.000  \n",
       "1                                           1.000                        0.000  \n",
       "2                                           1.000                        0.000  \n",
       "3                                           1.000                        0.000  \n",
       "4                                           1.000                        0.000  \n",
       "5                                           1.000                        0.000  \n",
       "6                                           0.000                        1.000  \n",
       "7                                           1.000                        0.000  \n",
       "8                                           1.000                        0.000  \n",
       "9                                           1.000                        0.000  \n",
       "10                                          1.000                        0.000  \n",
       "11                                          1.000                        0.000  \n",
       "12                                          1.000                        0.000  \n",
       "13                                          1.000                        0.000  \n",
       "14                                          1.000                        0.000  \n",
       "15                                          1.000                        0.000  \n",
       "16                                          1.000                        0.000  \n",
       "17                                          1.000                        0.000  \n",
       "18                                          1.000                        0.000  \n",
       "19                                          1.000                        0.000  \n",
       "20                                          1.000                        0.000  \n",
       "21                                          1.000                        0.000  \n",
       "22                                          1.000                        0.000  \n",
       "23                                          1.000                        0.000  \n",
       "24                                          1.000                        0.000  \n",
       "25                                          1.000                        0.000  \n",
       "26                                          1.000                        0.000  \n",
       "27                                          1.000                        0.000  \n",
       "28                                          0.000                        1.000  \n",
       "29                                          1.000                        0.000  \n",
       "...                                           ...                          ...  \n",
       "1833                                        0.000                        1.000  \n",
       "1834                                        0.000                        1.000  \n",
       "1835                                        0.000                        1.000  \n",
       "1836                                        0.000                        1.000  \n",
       "1837                                        0.000                        1.000  \n",
       "1838                                        0.000                        1.000  \n",
       "1839                                        0.000                        1.000  \n",
       "1840                                        0.000                        1.000  \n",
       "1841                                        0.000                        1.000  \n",
       "1842                                        0.000                        1.000  \n",
       "1843                                        0.000                        1.000  \n",
       "1844                                        0.000                        1.000  \n",
       "1845                                        0.000                        1.000  \n",
       "1846                                        0.000                        1.000  \n",
       "1847                                        0.000                        1.000  \n",
       "1848                                        0.000                        1.000  \n",
       "1849                                        0.000                        1.000  \n",
       "1850                                        0.000                        1.000  \n",
       "1851                                        0.000                        1.000  \n",
       "1852                                        0.000                        1.000  \n",
       "1853                                        0.000                        1.000  \n",
       "1854                                        0.000                        1.000  \n",
       "1855                                        0.000                        1.000  \n",
       "1856                                        0.000                        1.000  \n",
       "1857                                        0.000                        1.000  \n",
       "1858                                        0.000                        1.000  \n",
       "1859                                        0.000                        1.000  \n",
       "1860                                        0.000                        1.000  \n",
       "1861                                        0.000                        1.000  \n",
       "1862                                        0.000                        1.000  \n",
       "\n",
       "[1863 rows x 40 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(exclude = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/home/kshitiz/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "# Create empty dictionary called fitted_models\n",
    "fitted_models = {}\n",
    "\n",
    "# Loop through model pipelines, tuning each one and saving it to fitted_models\n",
    "for name, pipeline in pipelines.items():\n",
    "    # Create cross-validation object from pipeline and hyperparameters\n",
    "    model = GridSearchCV(pipelines[name], hyperparameters[name], cv = 10, n_jobs = -1)\n",
    "    \n",
    "    # Fit model on X_train, y_train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Store model in fitted_models[name] \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    # Print '{name} has been fitted'\n",
    "    print(name, 'has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Run this code to check that the models are of the correct type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "# Check that we have 5 cross-validation objects\n",
    "for key, value in fitted_models.items():\n",
    "    print( key, type(value) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "**Finally, run this code to check that the models have been fitted correctly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n",
      "dict_items([('lasso', GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=123,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)), ('ridge', GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=123, solver='auto', tol=0.001))]),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid={'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)), ('enet', GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
      "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
      "      random_state=123, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid={'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)), ('rf', GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decr...timators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid={'randomforestregressor__n_estimators': [200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33], 'randomforestregressor__max_depth': [5, 8, 15, 25, 30], 'randomforestregressor__min_samples_split': [2, 5, 10, 15, 100], 'randomforestregressor__min_samples_leaf': [1, 2, 5, 10]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)), ('gb', GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, mi...rs=100, presort='auto', random_state=123,\n",
      "             subsample=1.0, verbose=0, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=-1,\n",
      "       param_grid={'gradientboostingregressor__n_estimators': [100, 200], 'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2], 'gradientboostingregressor__max_depth': [1, 3, 5, 7, 9, 12, 15, 17, 25], 'gradientboostingregressor__subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))\n",
    "        \n",
    "print(fitted_models.items())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Now we're ready to evaluate how our models performed!\n",
    "\n",
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br id=\"evaluate\">\n",
    "# 5. Evaluate models and select winner\n",
    "\n",
    "Finally, it's time to evaluate our models and pick the best one.\n",
    "\n",
    "<br>\n",
    "Let's display the holdout $R^2$ score for each fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso is 0.309321321129175\n",
      "ridge is 0.3168057193514907\n",
      "enet is 0.34275978695602927\n",
      "rf is 0.49902889684787677\n",
      "gb is 0.4968115102205213\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_ for each fitted model\n",
    "for name, model in fitted_models.items():\n",
    "    print(name, \"is\", model.best_score_)\n",
    "    \n",
    "# lasso is 0.309321321129175\n",
    "# ridge is 0.3168057193514907\n",
    "# enet is 0.34275978695602927\n",
    "# rf is 0.4821423863134494\n",
    "# gb is 0.4887380873095676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enet': GridSearchCV(cv=10, error_score='raise',\n",
       "        estimator=Pipeline(memory=None,\n",
       "      steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "       random_state=123, selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "        fit_params=None, iid=True, n_jobs=-1,\n",
       "        param_grid={'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10], 'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=0),\n",
       " 'gb': GridSearchCV(cv=10, error_score='raise',\n",
       "        estimator=Pipeline(memory=None,\n",
       "      steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "              max_leaf_nodes=None, mi...rs=100, presort='auto', random_state=123,\n",
       "              subsample=1.0, verbose=0, warm_start=False))]),\n",
       "        fit_params=None, iid=True, n_jobs=-1,\n",
       "        param_grid={'gradientboostingregressor__n_estimators': [100, 200], 'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2], 'gradientboostingregressor__max_depth': [1, 3, 5, 7, 9, 12, 15, 17, 25], 'gradientboostingregressor__subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=0),\n",
       " 'lasso': GridSearchCV(cv=10, error_score='raise',\n",
       "        estimator=Pipeline(memory=None,\n",
       "      steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "    normalize=False, positive=False, precompute=False, random_state=123,\n",
       "    selection='cyclic', tol=0.0001, warm_start=False))]),\n",
       "        fit_params=None, iid=True, n_jobs=-1,\n",
       "        param_grid={'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=0),\n",
       " 'rf': GridSearchCV(cv=10, error_score='raise',\n",
       "        estimator=Pipeline(memory=None,\n",
       "      steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "            max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decr...timators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
       "        fit_params=None, iid=True, n_jobs=-1,\n",
       "        param_grid={'randomforestregressor__n_estimators': [200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33], 'randomforestregressor__max_depth': [5, 8, 15, 25, 30], 'randomforestregressor__min_samples_split': [2, 5, 10, 15, 100], 'randomforestregressor__min_samples_leaf': [1, 2, 5, 10]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=0),\n",
       " 'ridge': GridSearchCV(cv=10, error_score='raise',\n",
       "        estimator=Pipeline(memory=None,\n",
       "      steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "    normalize=False, random_state=123, solver='auto', tol=0.001))]),\n",
       "        fit_params=None, iid=True, n_jobs=-1,\n",
       "        param_grid={'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
       "        pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "        scoring=None, verbose=0)}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what you should see:\n",
    "\n",
    "    enet 0.342759786956\n",
    "    lasso 0.309321321129\n",
    "    ridge 0.316805719351\n",
    "    gb 0.48873808731\n",
    "    rf 0.480576134721\n",
    "\n",
    "\n",
    "If you get different numbers, check to see if you've set the <code style=\"color:steelblue\">random_state=</code> correctly for each of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import the <code style=\"color:steelblue\">r2_score()</code> and <code style=\"color:steelblue\">mean_absolute_error()</code> functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import r2_score and mean_absolute_error functions\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how the fitted models perform on our test set!\n",
    "\n",
    "<br>\n",
    "First, access your fitted random forest and display the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decr...timators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'randomforestregressor__n_estimators': [200], 'randomforestregressor__max_features': ['auto', 'sqrt', 0.33], 'randomforestregressor__max_depth': [5, 8, 15, 25, 30], 'randomforestregressor__min_samples_split': [2, 5, 10, 15, 100], 'randomforestregressor__min_samples_leaf': [1, 2, 5, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display fitted random forest object\n",
    "fitted_models['rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test set using the fitted random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test set using fitted random forest\n",
    "pred_rf = fitted_models['rf'].predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the scoring functions we imported to calculate and print $R^2$ and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.5533566772098171\n",
      "MAE is 70308.15024482376\n",
      "RMSE is 95399.75876049383\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print R^2 and MAE\n",
    "print(\"R2 is\", r2_score(y_test, pred_rf))\n",
    "print(\"MAE is\", mean_absolute_error(y_test, pred_rf))\n",
    "print(\"RMSE is\", np.sqrt(mean_squared_error(y_test, pred_rf)))\n",
    "\n",
    "# Old Metrics\n",
    "# R2 is 0.5737703464941731\n",
    "# MAE is 68361.8492225201\n",
    "# RMSE is 93194.1569781168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  importance\n",
      "insurance              0.667\n",
      "property_tax           0.159\n",
      "during_recession       0.031\n",
      "sqft                   0.027\n",
      "property_age           0.019\n",
      "median_age             0.014\n",
      "college_grad           0.013\n",
      "beauty_spas            0.009\n",
      "lot_size               0.008\n",
      "married                0.007\n"
     ]
    }
   ],
   "source": [
    "# Plot feature importance using Random Forests (Obtained from Grid Search)\n",
    "\n",
    "rf_model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
    "## Fit the model on your training data.\n",
    "rf_model.fit(X_train, y_train) \n",
    "## And score it on your testing data.\n",
    "rf_model.score(X_test, y_test)\n",
    "rf_feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "\n",
    "print(feature_importances[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  importance\n",
      "insurance              0.667\n",
      "property_tax           0.159\n",
      "during_recession       0.031\n",
      "sqft                   0.027\n",
      "property_age           0.019\n",
      "median_age             0.014\n",
      "college_grad           0.013\n",
      "beauty_spas            0.009\n",
      "lot_size               0.008\n",
      "married                0.007\n"
     ]
    }
   ],
   "source": [
    "# Plot feature importance as given by random forests (obtained by Random Search)\n",
    "\n",
    "rf_random = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=4, min_samples_split=5,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False)\n",
    "## Fit the model on your training data.\n",
    "rf_random.fit(X_train, y_train) \n",
    "## And score it on your testing data.\n",
    "rf_random.score(X_test, y_test)\n",
    "rf_random.feature_importances = pd.DataFrame(rf_random.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',\n",
    "                                                                        ascending=False)\n",
    "print(feature_importances[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next exercise, we'll evaluate all of our fitted models on the test set and pick the winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "## <span style=\"color:RoyalBlue\">Exercise 5.5</span>\n",
    "\n",
    "**Use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.**\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "----------\n",
      "R^2:  0.4093134589320906\n",
      "MAE:  84963.5598921746\n",
      "RMSE:  109709.79191583135 \n",
      "\n",
      "ridge\n",
      "----------\n",
      "R^2:  0.4096813144454988\n",
      "MAE:  84923.9964122126\n",
      "RMSE:  109675.62520116064 \n",
      "\n",
      "enet\n",
      "----------\n",
      "R^2:  0.4059130767577358\n",
      "MAE:  86249.57730050449\n",
      "RMSE:  110025.11979836859 \n",
      "\n",
      "rf\n",
      "----------\n",
      "R^2:  0.5533566772098171\n",
      "MAE:  70308.15024482376\n",
      "RMSE:  95399.75876049383 \n",
      "\n",
      "gb\n",
      "----------\n",
      "R^2:  0.550194234247441\n",
      "MAE:  70380.09146685422\n",
      "RMSE:  95736.90041807796 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code here\n",
    "for name, model in fitted_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print(\"----------\")\n",
    "    print(\"R^2: \", r2_score(y_test, pred))\n",
    "    print(\"MAE: \", mean_absolute_error(y_test, pred))\n",
    "    print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, pred)), \"\\n\")\n",
    "    \n",
    "    # Old Metrics (Simple Grid Search with few paramters)\n",
    "#     lasso\n",
    "# ----------\n",
    "# R^2:  0.4093134589320906\n",
    "# MAE:  84963.5598921746\n",
    "# RMSE:  109709.79191583135 \n",
    "\n",
    "# ridge\n",
    "# ----------\n",
    "# R^2:  0.4096813144454988\n",
    "# MAE:  84923.9964122126\n",
    "# RMSE:  109675.62520116064 \n",
    "\n",
    "# enet\n",
    "# ----------\n",
    "# R^2:  0.4059130767577358\n",
    "# MAE:  86249.57730050449\n",
    "# RMSE:  110025.11979836859 \n",
    "\n",
    "# rf\n",
    "# ----------\n",
    "# R^2:  0.5737703464941731\n",
    "# MAE:  68361.8492225201\n",
    "# RMSE:  93194.1569781168 \n",
    "\n",
    "# gb\n",
    "# ----------\n",
    "# R^2:  0.5344072772726018\n",
    "# MAE:  70828.57580311719\n",
    "# RMSE:  97402.46445017045 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, ask yourself these questions to pick the winning model:**\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "\n",
    "> Random forest\n",
    "\n",
    "* Which model had the lowest mean absolute error?\n",
    "\n",
    "> Random forest\n",
    "\n",
    "* Are these two models the same one?\n",
    "\n",
    "> Yes\n",
    "\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "\n",
    "> Yes\n",
    "\n",
    "* **Does it satisfy our win condition?**\n",
    "\n",
    "> Yes, its mean absolute error is less than \\$70,000!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, let's plot the performance of the winning model on the test set. Run the code below.**\n",
    "* It first plots a scatter plot.\n",
    "* Then, it plots predicted transaction price on the X-axis.\n",
    "* Finally, it plots actual transaction price on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f037c36b4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gb_pred = fitted_models['rf'].predict(X_test)\n",
    "plt.scatter(gb_pred, y_test)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal?\n",
    "\n",
    "<br>\n",
    "<hr style=\"border-color:royalblue;background-color:royalblue;height:1px;\">\n",
    "\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Finally, let's save the winning model.\n",
    "\n",
    "Great job! You've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "First, let's take a look at the data type of your winning model.\n",
    "\n",
    "***Run each code cell below after completing the exercises above.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> data type. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "In that case, we can use the <code style=\"color:steelblue\">best\\_estimator_</code> method to access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fitted_models['rf'].best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we output that object directly, we can also see the winning values for our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
       "           oob_score=False, random_state=123, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See? The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>\n",
    "\n",
    "Great, now let's import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the winning <code style=\"color:steelblue\">Pipeline</code> object into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner.\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "\n",
    "<p>This also marks the end of <span style=\"color:royalblue\">Project 2: Real-Estate Tycoon</span>!</p>\n",
    "<p>In the next project, you'll practice the entire machine learning workflow again, except for <strong>classification</strong>. In addition, we'll provide less formal guidance and introduce some new concepts.</p><p>Finally, in this project, you trained a kick-ass model and saved it as a pickle file. In the next project, we'll show you how to take <strong>project delivery</strong> a step further by creating custom model classes that can apply your final model to raw data.</p>\n",
    "\n",
    "<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n",
    "[**Back to Contents**](#toc)\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
